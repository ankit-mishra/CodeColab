{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKxMLoFPkjDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEyPdJallxgv",
        "colab_type": "text"
      },
      "source": [
        "This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. \n",
        "If use_bias is True, a bias vector is created and added to the outputs. Finally, if activation is not None, it is applied to the outputs as well.\n",
        "\n",
        "When using this layer as the first layer in a model, provide the keyword argument input_shape (tuple of integers, does not include the sample axis), e.g. input_shape=(128, 128, 3) for 128x128 RGB pictures in data_format=\"channels_last\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atUch32kkLL3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ecdd5272-4e21-4f2b-8a0d-917efa655a68"
      },
      "source": [
        "# The inputs are 28x28 RGB images with `channels_last` and the batch  \n",
        "# size is 4.  \n",
        "input_shape = (4, 28, 28, 3)\n",
        "x = tf.random.normal(input_shape)\n",
        "y = tf.keras.layers.Conv2D(2, 3, activation='relu', input_shape=input_shape[1:])(x)\n",
        "print(y.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4, 26, 26, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nwwxux3SkvXb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b0ca06a8-d30d-44d4-d83d-519d1115a46b"
      },
      "source": [
        "# With `dilation_rate` as 2.  \n",
        "input_shape = (4, 28, 28, 3)\n",
        "x = tf.random.normal(input_shape)\n",
        "y = tf.keras.layers.Conv2D(2, 3, activation='relu', dilation_rate=2, input_shape=input_shape[1:])(x)\n",
        "print(y.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4, 24, 24, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6TaoNH6lHM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# With `padding` as \"same\".  \n",
        "input_shape = (4, 28, 28, 3)\n",
        "x = tf.random.normal(input_shape)\n",
        "y = tf.keras.layers.Conv2D(2, 3, activation='relu', padding=\"same\", input_shape=input_shape[1:])(x)\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rvLdHe0lbUs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# With extended batch shape [4, 7]:  \n",
        "input_shape = (4, 7, 28, 28, 3)\n",
        "x = tf.random.normal(input_shape)\n",
        "y = tf.keras.layers.Conv2D(2, 3, activation='relu', input_shape=input_shape[2:])(x)\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9E_GW0_jl92S",
        "colab_type": "text"
      },
      "source": [
        "Reference : https://keras.io/api/layers/convolution_layers/convolution2d/"
      ]
    }
  ]
}