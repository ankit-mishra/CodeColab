{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_Tensorflow_GradientTape.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndsAg6jAulfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Prepare an optimizer.\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "# Prepare a loss function.\n",
        "loss_fn = tf.keras.losses.kl_divergence\n",
        "\n",
        "# Iterate over the batches of a dataset.\n",
        "for inputs, targets in dataset:\n",
        "    # Open a GradientTape.\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Forward pass.\n",
        "        predictions = model(inputs)\n",
        "        # Compute the loss value for this batch.\n",
        "        loss_value = loss_fn(targets, predictions)\n",
        "\n",
        "    # Get gradients of loss wrt the weights.\n",
        "    gradients = tape.gradient(loss_value, model.trainable_weights)\n",
        "    # Update the weights of the model.\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}